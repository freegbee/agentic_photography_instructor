{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae087380d1aff2",
   "metadata": {},
   "source": [
    "# Notebook to visually load some sample images and transform them\n",
    "\n",
    "The aim is to make some easy visualization of the progress/effect of various the image transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3ebd1b655058d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T16:29:08.222728Z",
     "start_time": "2025-11-23T16:29:05.818507Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, Subset\n",
    "\n",
    "from image_aquisition.BasicTestDataset import BasicTestDataset\n",
    "from utils.ConfigLoader import ConfigLoader\n",
    "from transformation_agent import StaticTransformationAgentFactory\n",
    "from utils.Registries import AGENT_FACTORY_REGISTRY"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'image_aquisition.BasicTestDataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DataLoader, Dataset, RandomSampler, SequentialSampler, Subset\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mimage_aquisition\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mBasicTestDataset\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BasicTestDataset\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mConfigLoader\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ConfigLoader\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformation_agent\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StaticTransformationAgentFactory\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'image_aquisition.BasicTestDataset'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "bdb12a8208e0ebeb",
   "metadata": {},
   "source": [
    "## Adjust/set environment variables - no fun with that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8445215e909d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ENV_NAME=HOLGER\n",
    "os.chdir(r\"C:\\Users\\holge\\Dokumente (lokal)\\CASML4SE\\agentic_photography_instructor\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47bf1bf2dd8596",
   "metadata": {},
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de125a755a018888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_keep_size(batch):\n",
    "    # Gibt einfach die Liste der einzelnen Tensoren zurück\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f0f77ba40e980",
   "metadata": {},
   "source": [
    "## Prepare and initialize DataLoader\n",
    "\n",
    "The dataloader will provide batches of images up to a given number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd02fb376ac10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config: Dict = ConfigLoader().load(env=os.environ[\"ENV_NAME\"])\n",
    "image_dir = config[\"dev\"][\"cloned_image_dir\"]\n",
    "dataset: Dataset = BasicTestDataset(image_dir)\n",
    "print(f\"Number of images in {image_dir}: {len(dataset)}\")\n",
    "\n",
    "# sampler to return only 10 random samples from the dataset. Not sure what replacement=True means\n",
    "num_samples = min(10, len(dataset))\n",
    "rndSampler = RandomSampler(dataset, replacement=True, num_samples=num_samples)\n",
    "subsetSampler = SequentialSampler(Subset(dataset, range(num_samples)))\n",
    "\n",
    "# collate_keep_size sorgt dafür, dass die Bilder ihre Originalgrösse behalten können. Standatdmässig müssten alle Bilder die gleiche Grösse haben, was wir aber nicht wollen, da wir hin diesem Moment die Bilder untransformiert lassen wollen.\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_keep_size, sampler=subsetSampler)\n",
    "\n",
    "dataloader.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a6b091647f151",
   "metadata": {},
   "source": [
    "## Prepare transformers and transformation agents\n",
    "\n",
    "The transformation agents will prcess the images coming from the data loader. We will for each image render the original image the label and the transformed image. By this we are able to get a first impression what the various transformers will produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fce236d2fff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    # for every image in the batch\n",
    "    for image, path, filename in batch:\n",
    "        # for every factory (that produces a list of transformation agents\n",
    "        image_rgb = image[..., ::-1]\n",
    "        for factory_name in AGENT_FACTORY_REGISTRY.keys():\n",
    "            for agent in AGENT_FACTORY_REGISTRY.get(factory_name).create_agents():\n",
    "                image_clone = image.copy()\n",
    "                transformed_image, label = agent.transform(image_clone)\n",
    "                # Visualisierung\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.suptitle(f\"{filename} | Label: {label}\", fontsize=12)\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(image_rgb)\n",
    "                plt.title(\"Original\")\n",
    "                plt.axis('off')\n",
    "                plt.subplot(1, 2, 2)\n",
    "                if transformed_image.ndim == 2:\n",
    "                    # grayscaled image has only 2 dimensions. We need to render accordingly\n",
    "                    plt.imshow(transformed_image, cmap=\"gray\")\n",
    "                else:\n",
    "                    transformed_image_rgb = transformed_image[..., ::-1]\n",
    "                    plt.imshow(transformed_image_rgb)\n",
    "                plt.title(\"Transformed\")\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
