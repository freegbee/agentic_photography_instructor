name: ${NAME}
services:
#  data-service:
#    build:
#      context: image-acquisition-service
#      dockerfile: Dockerfile
#    container_name: image-acquisition-service
#    environment:
#      # ENV_NAME=docker-Eintrag sorgt dafür, dass die os.environment Variable gesetzt wird. (Verwendung vom docker.yaml)
#      - ENV_NAME=docker
#      # PYTHONPATH=/app/src-Eintrag sorgt dafür, dass Python Module(-Import) relativ zum /src-Verzeichnis finden kann
#      - PYTHONPATH=/app/src
#    volumes:
#      - resources:/app/volumes/resources
#      - ../src:/app/src
#      - ../configs:/app/configs
#    networks:
#      - ml-network

  image-acquisition-service:
    build:
      context: image-acquisition-service
      dockerfile: Dockerfile
    container_name: image-acquisition-service
    ports:
      - "${IMAGE_ACQUISITION_PORT}:${IMAGE_ACQUISITION_PORT}"
    environment:
      - ENV_NAME=docker
      - PYTHONPATH=/app
      - IMAGE_VOLUME_PATH=/app/volumes/resources
    command: >
      python -m uvicorn image_acquisition.acquisition_server.AcquisitionServer:app
      --host 0.0.0.0
      --port ${IMAGE_ACQUISITION_PORT}
      --log-level info
    volumes:
      - resources:/app/volumes/resources
      - ../src/:/app
      - ../configs:/app/configs
    depends_on:
      - prometheus
    networks:
      - ml-network

  juror-service:
    build:
      context: juror-service
      dockerfile: Dockerfile
    container_name: juror-service
    ports:
      - "${JUROR_PORT}:${JUROR_PORT}"
    environment:
      - ENV_NAME=docker
      - PYTHONPATH=/app
    command: >
      python -m uvicorn juror_server.JurorServer:app
      --host 0.0.0.0
      --port ${JUROR_PORT}
      --log-level info
    volumes:
      - ../src/:/app
    depends_on:
      - prometheus
    networks:
      - ml-network
    # Folgender Block sorgt dafür, dass der Container auf eine GPU mit CUDA zugreifen kann.
    # Offen, ob das auf dem Mac stört und wir profile brauchen, oder nicht
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

  train:
    build:
      context: train
      dockerfile: Dockerfile
    container_name: train
    environment:
      - ENV_NAME=docker
      - PYTHONPATH=/app/src
      - MLFLOW_TRACKING_URI=http://mlflow:${MLFLOW_PORT}
    volumes:
      - resources:/app/volumes/resources
      - ../src:/app/src
      - ../configs:/app/configs
      - ../test:/app/test
    depends_on:
      - mlflow
    networks:
      - ml-network

  mlflow:
    build:
      context: mlflow
      dockerfile: Dockerfile
    container_name: mlflow
    ports:
      - "${MLFLOW_PORT}:${MLFLOW_PORT}"
    volumes:
      # Artefakte (Runs) persistent speichern
      - mlruns:/mlruns
      # Backend-DB persistent speichern
      - mlflow:/mlflow
    command: >
      mlflow server
      --host 0.0.0.0
      --port ${MLFLOW_PORT}
      --backend-store-uri ${MLFLOW_BACKEND_STORE_URI}
      --default-artifact-root ${MLFLOW_ARTIFACT_ROOT}
      --allowed-hosts "*"
    networks:
      - ml-network

  prometheus:
    build:
      context: prometheus
      dockerfile: Dockerfile
    container_name: prometheus
    ports:
      - "${MONITORING_PROMETHEUS_PORT}:${MONITORING_PROMETHEUS_PORT}"
    environment:
      IMAGE_ACQUISITION_PORT: "${IMAGE_ACQUISITION_PORT}"
      JUROR_PORT: "${JUROR_PORT}"
      MLFLOW_PORT: "${MLFLOW_PORT}"
      MONITORING_PROMETHEUS_PORT: "${MONITORING_PROMETHEUS_PORT}"
    volumes:
      - prometheus_data:/prometheus
      - ./prometheus/prometheus.yml.template:/etc/prometheus/prometheus.yml.template:ro
    networks:
      - ml-network

  grafana:
    build:
      context: grafana
      dockerfile: Dockerfile
    container_name: grafana
    ports:
      - "${MONITORING_GRAFANA_PORT}:${MONITORING_GRAFANA_PORT}"
    environment:
      MONITORING_GRAFANA_PORT: "${MONITORING_GRAFANA_PORT}"
      GF_SERVER_HTTP_PORT: "${MONITORING_GRAFANA_PORT}"
      GF_SERVER_ROOT_URL: "http://localhost:${MONITORING_GRAFANA_PORT}"
      GF_USERS_ALLOW_SIGN_UP: "false"
      PROMETHEUS_URL: "http://prometheus:${MONITORING_PROMETHEUS_PORT}"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - ml-network
    depends_on:
      - prometheus

volumes:
  test:
    external: true
  mlflow:
    name: mlflow
    driver: local
  mlruns:
    name: mlruns
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  resources:
    name: resources
    driver: local

networks:
  ml-network:
    driver: bridge